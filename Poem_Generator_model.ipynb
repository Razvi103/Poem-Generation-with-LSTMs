{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhfQeaOPkaiEc17bRwES04",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Razvi103/Poem-Generation-with-LSTMs/blob/main/Poem_Generator_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0m8Yi9T1vC1w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, GlobalMaxPooling1D, Embedding, Dropout\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_csv = pd.read_csv(\"Poem_classification - train_data.csv\")\n",
        "test_csv = pd.read_csv(\"Poem_classification - test_data.csv\")\n",
        "\n",
        "print(train_csv.head())\n",
        "print(test_csv.head())\n",
        "\n",
        "# Clean the text data by removing unicode '\\xa0 and hyphens from the Poem columns\n",
        "train_csv['Poem'] = train_csv['Poem'].str.replace(r'\\b-\\w+', '', regex=True).str.replace(r'\\b\\w+-\\w+\\b', ' ', regex=True).str.replace('\\xa0', ' ').str.strip()\n",
        "test_csv['Poem'] = test_csv['Poem'].str.replace(r'\\b-\\w+', '', regex=True).str.replace(r'\\b\\w+-\\w+\\b', ' ', regex=True).str.replace('\\xa0', ' ').str.strip()\n",
        "\n",
        "# we only need the poem columns from the dataset because we are not doing classification\n",
        "train_data = train_csv.iloc[1:, 1:].values\n",
        "train_data_2 = test_csv.iloc[1:, 1:].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76qf4RpmwxIV",
        "outputId": "628fcf2e-1b09-42de-eb6b-8c9fdb48eeb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Genre                                               Poem\n",
            "0  Music                                                NaN\n",
            "1  Music                In the thick brushthey spend the...\n",
            "2  Music     Storms are generous.                       ...\n",
            "3  Music   —After Ana Mendieta Did you carry around the ...\n",
            "4  Music   for Aja Sherrard at 20The portent may itself ...\n",
            "   Genre                                               Poem\n",
            "0  Music  A woman walks by the bench I’m sitting onwith ...\n",
            "1  Music  Because I am a boy, the untouchability of beau...\n",
            "2  Music  Because today we did not leave this world,We n...\n",
            "3  Music  Big Bend has been here, been here. Shouldn’t i...\n",
            "4  Music  I put shells there, along the lip of the road....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Combine train and test datasets from kaggle and reshape it\n",
        "train_data_combined = np.vstack((train_data, train_data_2))\n",
        "train_data_combined = train_data_combined.reshape(-1)\n",
        "\n",
        "\n",
        "\n",
        "# a list of all the indexes where floats are located\n",
        "float_indexes = []\n",
        "max_len = 0\n",
        "for i in range(len(train_data_combined)):\n",
        "  if not isinstance(train_data_combined[i], str):\n",
        "    float_indexes.append(i)\n",
        "  else:\n",
        "    train_data_combined[i] = train_data_combined[i].lower()\n",
        "    # count the maximum number of words in a poem\n",
        "    if len(train_data_combined[i]) > max_len:\n",
        "      max_len = len(train_data_combined[i])\n",
        "\n",
        "# remove all the floats that are not part of a string\n",
        "train_data_combined = np.delete(train_data_combined, float_indexes)\n",
        "print(max_len)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Joz7p8MH0M_S",
        "outputId": "a815c076-2ebe-4217-eab2-e6678d0a83f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize tokenizer, fit on text and tokenize the sequences\n",
        "MAX_VOCAB_LENGTH = 10000\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_LENGTH)\n",
        "tokenizer.fit_on_texts(train_data_combined)\n",
        "sequences = tokenizer.texts_to_sequences(train_data_combined)"
      ],
      "metadata": {
        "id": "IEp-vogp2Jys"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the vocabulary length\n",
        "vocabulary_length = len(tokenizer.word_index)\n",
        "print(vocabulary_length)\n",
        "\n",
        "SEQ_LENGTH = 40\n",
        "\n",
        "# transform the tokenized sequences such that we have sequantial data\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for poem in sequences:\n",
        "  for i in range(len(poem) - SEQ_LENGTH):\n",
        "    # append every SEQ_LENGTH words to X_seq and SEQ_LENGTH + 1 th word to y_seq\n",
        "    X_seq.append(poem[i : i + SEQ_LENGTH])\n",
        "    y_seq.append(poem[i + SEQ_LENGTH ])\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "\n",
        "print(X_seq.shape, y_seq.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB6JV3hHCInZ",
        "outputId": "3c89ffcf-8f63-4f30-9a4a-bd8ad33e2d42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9628\n",
            "(10646, 40) (10646,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input for a timeseries where data is stored as N x T x D is of shape T X D\n",
        "# N - num of records\n",
        "# T - sequence length\n",
        "# D = num of features, (in our case 1)\n",
        "inputs = Input(shape=(SEQ_LENGTH, ))\n",
        "\n",
        "# embedding layer with dimension 150 for our 10000 words vocabulary\n",
        "x = Embedding(vocabulary_length + 1, 150)(inputs)\n",
        "\n",
        "# two LSTM layers with Droupout layers in between for regularization\n",
        "x = LSTM(512, return_sequences=True)(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = LSTM(512, return_sequences=False)(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# One Dense layer for complexity\n",
        "\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# final Dense layer for predicting the next word in the sequence,\n",
        "# vocab_length + 1 units because tokenizer starts indexing from 1, we have a class for each word\n",
        "\n",
        "outputs = Dense(vocabulary_length + 1, activation='softmax')(x)\n",
        "\n",
        "# instantiate the model\n",
        "model = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "cgvZAEZwKE1M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a custom perplexity function\n",
        "# perplexity is a better metric for text generation\n",
        "def perplexity(y_true, y_pred):\n",
        "    # convert y_pred to probabilities\n",
        "    # clip to avoid log(0) errors\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-10, 1.0)\n",
        "    cross_entropy = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
        "    perplexity_value = tf.exp(tf.reduce_mean(cross_entropy))\n",
        "    return perplexity_value\n"
      ],
      "metadata": {
        "id": "5WCLZijcFSAb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model using the rmsprop optimizer, which is generally good for rnn's\n",
        "# loss is sparse_categorical_crossentropy because we are doing multi-label classification\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=[perplexity, 'accuracy'])"
      ],
      "metadata": {
        "id": "lwreiMBwN8XL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(X_seq, y_seq, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb4X7FnEO9Yz",
        "outputId": "89357e59-043d-46e1-ccf4-bc710870eef9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.0557 - loss: 7.7925 - perplexity: 3309.1140\n",
            "Epoch 2/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.0634 - loss: 7.3086 - perplexity: 1631.7969\n",
            "Epoch 3/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0590 - loss: 7.2422 - perplexity: 1545.3173\n",
            "Epoch 4/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0673 - loss: 7.1593 - perplexity: 1455.1844\n",
            "Epoch 5/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.0635 - loss: 7.1336 - perplexity: 1385.1991\n",
            "Epoch 6/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0656 - loss: 7.0927 - perplexity: 1358.9449\n",
            "Epoch 7/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0668 - loss: 7.1089 - perplexity: 1376.6846\n",
            "Epoch 8/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0642 - loss: 7.0856 - perplexity: 1330.4280\n",
            "Epoch 9/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0696 - loss: 7.0168 - perplexity: 1258.5232\n",
            "Epoch 10/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0658 - loss: 7.0213 - perplexity: 1263.8547\n",
            "Epoch 11/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0655 - loss: 6.9981 - perplexity: 1218.5956\n",
            "Epoch 12/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0685 - loss: 6.9939 - perplexity: 1220.5443\n",
            "Epoch 13/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.0665 - loss: 7.0187 - perplexity: 1244.5427\n",
            "Epoch 14/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0639 - loss: 6.9813 - perplexity: 1234.9213\n",
            "Epoch 15/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0726 - loss: 6.8853 - perplexity: 1082.6477\n",
            "Epoch 16/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0691 - loss: 6.9078 - perplexity: 1137.0320\n",
            "Epoch 17/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0714 - loss: 6.8653 - perplexity: 1078.6984\n",
            "Epoch 18/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0714 - loss: 6.8435 - perplexity: 1070.2062\n",
            "Epoch 19/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0738 - loss: 6.7622 - perplexity: 955.3524\n",
            "Epoch 20/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0735 - loss: 6.7322 - perplexity: 946.3109\n",
            "Epoch 21/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0738 - loss: 6.7411 - perplexity: 972.9981\n",
            "Epoch 22/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0793 - loss: 6.6977 - perplexity: 914.3187\n",
            "Epoch 23/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.0822 - loss: 6.6458 - perplexity: 888.6412\n",
            "Epoch 24/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0822 - loss: 6.5929 - perplexity: 822.7360\n",
            "Epoch 25/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0865 - loss: 6.5025 - perplexity: 774.1453\n",
            "Epoch 26/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0817 - loss: 6.5344 - perplexity: 777.6877\n",
            "Epoch 27/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.0919 - loss: 7.5326 - perplexity: 824.4861\n",
            "Epoch 28/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0888 - loss: 6.4822 - perplexity: 770.9734\n",
            "Epoch 29/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.0928 - loss: 6.4479 - perplexity: 733.2513\n",
            "Epoch 30/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0975 - loss: 6.4178 - perplexity: 711.9388\n",
            "Epoch 31/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1006 - loss: 6.3077 - perplexity: 642.6607\n",
            "Epoch 32/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1103 - loss: 6.2845 - perplexity: 608.6674\n",
            "Epoch 33/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1092 - loss: 6.3018 - perplexity: 640.2086\n",
            "Epoch 34/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1135 - loss: 6.2660 - perplexity: 609.2344\n",
            "Epoch 35/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1207 - loss: 6.2075 - perplexity: 569.3083\n",
            "Epoch 36/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1195 - loss: 6.2622 - perplexity: 621.8398\n",
            "Epoch 37/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1195 - loss: 6.2468 - perplexity: 608.5306\n",
            "Epoch 38/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1220 - loss: 6.1851 - perplexity: 553.9644\n",
            "Epoch 39/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.1270 - loss: 6.2074 - perplexity: 599.8043\n",
            "Epoch 40/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1363 - loss: 6.1394 - perplexity: 534.4612\n",
            "Epoch 41/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1400 - loss: 6.0805 - perplexity: 514.6238\n",
            "Epoch 42/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.1382 - loss: 6.1319 - perplexity: 542.4833\n",
            "Epoch 43/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1411 - loss: 6.0731 - perplexity: 510.8496\n",
            "Epoch 44/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1425 - loss: 6.1022 - perplexity: 505.3076\n",
            "Epoch 45/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.1434 - loss: 5.9678 - perplexity: 450.3786\n",
            "Epoch 46/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.1476 - loss: 5.8308 - perplexity: 400.0901\n",
            "Epoch 47/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1535 - loss: 5.7952 - perplexity: 382.3539\n",
            "Epoch 48/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1538 - loss: 5.7163 - perplexity: 364.2862\n",
            "Epoch 49/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1658 - loss: 5.6650 - perplexity: 350.2785\n",
            "Epoch 50/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1587 - loss: 5.7114 - perplexity: 364.0593\n",
            "Epoch 51/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1567 - loss: 5.7393 - perplexity: 356.7753\n",
            "Epoch 52/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1739 - loss: 5.6602 - perplexity: 356.2054\n",
            "Epoch 53/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1772 - loss: 5.6366 - perplexity: 327.5980\n",
            "Epoch 54/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1819 - loss: 5.6309 - perplexity: 325.9991\n",
            "Epoch 55/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1814 - loss: 5.6385 - perplexity: 330.1889\n",
            "Epoch 56/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.1855 - loss: 5.5418 - perplexity: 305.6020\n",
            "Epoch 57/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1886 - loss: 5.5373 - perplexity: 304.2817\n",
            "Epoch 58/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1838 - loss: 5.6369 - perplexity: 330.4419\n",
            "Epoch 59/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1882 - loss: 5.5673 - perplexity: 325.7303\n",
            "Epoch 60/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1963 - loss: 5.4946 - perplexity: 288.5581\n",
            "Epoch 61/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.1947 - loss: 5.5848 - perplexity: 311.4078\n",
            "Epoch 62/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.2060 - loss: 5.4690 - perplexity: 275.2445\n",
            "Epoch 63/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.1975 - loss: 5.5714 - perplexity: 313.7226\n",
            "Epoch 64/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2018 - loss: 5.5057 - perplexity: 302.3599\n",
            "Epoch 65/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2098 - loss: 5.4927 - perplexity: 286.5462\n",
            "Epoch 66/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2173 - loss: 5.3795 - perplexity: 263.0705\n",
            "Epoch 67/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2083 - loss: 5.4249 - perplexity: 279.0595\n",
            "Epoch 68/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2097 - loss: 5.3554 - perplexity: 250.0105\n",
            "Epoch 69/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2186 - loss: 5.3439 - perplexity: 255.0380\n",
            "Epoch 70/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.2262 - loss: 5.3648 - perplexity: 256.0567\n",
            "Epoch 71/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2287 - loss: 5.3202 - perplexity: 246.2572\n",
            "Epoch 72/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.2263 - loss: 5.3419 - perplexity: 250.8268\n",
            "Epoch 73/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2324 - loss: 5.2908 - perplexity: 233.1835\n",
            "Epoch 74/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2318 - loss: 5.3006 - perplexity: 245.4343\n",
            "Epoch 75/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2303 - loss: 5.2756 - perplexity: 231.7882\n",
            "Epoch 76/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.2404 - loss: 6.2144 - perplexity: 306.6437\n",
            "Epoch 77/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2447 - loss: 5.2092 - perplexity: 227.2512\n",
            "Epoch 78/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2446 - loss: 5.2396 - perplexity: 227.8347\n",
            "Epoch 79/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2475 - loss: 5.1812 - perplexity: 210.6334\n",
            "Epoch 80/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2440 - loss: 5.2188 - perplexity: 218.4384\n",
            "Epoch 81/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2541 - loss: 5.1437 - perplexity: 202.9942\n",
            "Epoch 82/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2547 - loss: 5.1437 - perplexity: 202.9096\n",
            "Epoch 83/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2676 - loss: 5.1466 - perplexity: 200.8188\n",
            "Epoch 84/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2598 - loss: 5.1657 - perplexity: 216.4401\n",
            "Epoch 85/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2617 - loss: 5.0871 - perplexity: 194.1680\n",
            "Epoch 86/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2736 - loss: 5.0983 - perplexity: 205.2365\n",
            "Epoch 87/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2636 - loss: 5.1289 - perplexity: 208.2561\n",
            "Epoch 88/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2791 - loss: 5.1191 - perplexity: 202.0751\n",
            "Epoch 89/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2809 - loss: 5.1150 - perplexity: 205.6635\n",
            "Epoch 90/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2899 - loss: 4.9877 - perplexity: 173.2140\n",
            "Epoch 91/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2896 - loss: 5.0138 - perplexity: 188.7865\n",
            "Epoch 92/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2993 - loss: 4.9937 - perplexity: 178.2168\n",
            "Epoch 93/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2883 - loss: 5.0126 - perplexity: 196.9760\n",
            "Epoch 94/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2958 - loss: 4.9305 - perplexity: 169.6585\n",
            "Epoch 95/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3027 - loss: 4.7510 - perplexity: 142.4015\n",
            "Epoch 96/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2917 - loss: 4.7524 - perplexity: 140.5077\n",
            "Epoch 97/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2947 - loss: 4.7435 - perplexity: 137.7962\n",
            "Epoch 98/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2956 - loss: 4.7284 - perplexity: 134.4507\n",
            "Epoch 99/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3077 - loss: 4.6922 - perplexity: 133.2177\n",
            "Epoch 100/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3039 - loss: 4.7511 - perplexity: 137.3229\n",
            "Epoch 101/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3159 - loss: 4.8144 - perplexity: 151.8294\n",
            "Epoch 102/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3064 - loss: 4.8295 - perplexity: 147.9747\n",
            "Epoch 103/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3125 - loss: 4.8966 - perplexity: 159.3554\n",
            "Epoch 104/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3285 - loss: 4.7847 - perplexity: 146.7512\n",
            "Epoch 105/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3260 - loss: 4.9154 - perplexity: 164.8070\n",
            "Epoch 106/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3211 - loss: 4.9226 - perplexity: 167.8325\n",
            "Epoch 107/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3358 - loss: 4.8994 - perplexity: 165.0631\n",
            "Epoch 108/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3332 - loss: 4.9769 - perplexity: 174.6912\n",
            "Epoch 109/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3397 - loss: 4.8542 - perplexity: 158.0551\n",
            "Epoch 110/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3397 - loss: 4.8446 - perplexity: 156.3311\n",
            "Epoch 111/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3500 - loss: 4.8150 - perplexity: 143.7881\n",
            "Epoch 112/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3436 - loss: 4.7269 - perplexity: 136.5714\n",
            "Epoch 113/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3502 - loss: 4.6325 - perplexity: 123.9689\n",
            "Epoch 114/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3637 - loss: 4.5060 - perplexity: 107.3430\n",
            "Epoch 115/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3654 - loss: 4.4957 - perplexity: 106.3282\n",
            "Epoch 116/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3748 - loss: 4.4121 - perplexity: 102.8115\n",
            "Epoch 117/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3614 - loss: 4.5645 - perplexity: 115.8536\n",
            "Epoch 118/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3760 - loss: 4.5351 - perplexity: 116.2731\n",
            "Epoch 119/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3870 - loss: 4.4523 - perplexity: 105.4755\n",
            "Epoch 120/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3775 - loss: 4.4276 - perplexity: 106.4483\n",
            "Epoch 121/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3864 - loss: 4.3963 - perplexity: 97.9504\n",
            "Epoch 122/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3838 - loss: 4.4227 - perplexity: 100.4335\n",
            "Epoch 123/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3776 - loss: 4.3820 - perplexity: 96.4217\n",
            "Epoch 124/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3849 - loss: 4.2453 - perplexity: 85.7737\n",
            "Epoch 125/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3964 - loss: 4.2021 - perplexity: 82.8805\n",
            "Epoch 126/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3925 - loss: 4.1650 - perplexity: 78.8573\n",
            "Epoch 127/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3960 - loss: 4.1731 - perplexity: 79.8805\n",
            "Epoch 128/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.3922 - loss: 4.1994 - perplexity: 78.6595\n",
            "Epoch 129/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4003 - loss: 4.1599 - perplexity: 77.5436\n",
            "Epoch 130/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3992 - loss: 4.2004 - perplexity: 78.7865\n",
            "Epoch 131/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3976 - loss: 4.2741 - perplexity: 87.0457\n",
            "Epoch 132/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.3947 - loss: 4.3034 - perplexity: 88.8504\n",
            "Epoch 133/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3990 - loss: 4.2532 - perplexity: 87.4563\n",
            "Epoch 134/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4059 - loss: 4.2960 - perplexity: 88.0028\n",
            "Epoch 135/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.4079 - loss: 4.3035 - perplexity: 91.2443\n",
            "Epoch 136/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4125 - loss: 4.2764 - perplexity: 88.8982\n",
            "Epoch 137/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4029 - loss: 4.4186 - perplexity: 100.1824\n",
            "Epoch 138/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4200 - loss: 4.3142 - perplexity: 96.0996\n",
            "Epoch 139/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4089 - loss: 4.4497 - perplexity: 101.8183\n",
            "Epoch 140/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4151 - loss: 4.3946 - perplexity: 101.2163\n",
            "Epoch 141/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4297 - loss: 4.3150 - perplexity: 97.3314\n",
            "Epoch 142/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4332 - loss: 4.2573 - perplexity: 87.3398\n",
            "Epoch 143/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4328 - loss: 4.3412 - perplexity: 92.0574\n",
            "Epoch 144/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4353 - loss: 4.3424 - perplexity: 95.5872\n",
            "Epoch 145/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4303 - loss: 4.2998 - perplexity: 89.3303\n",
            "Epoch 146/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4192 - loss: 4.3410 - perplexity: 92.3045\n",
            "Epoch 147/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4280 - loss: 4.3095 - perplexity: 89.9918\n",
            "Epoch 148/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4361 - loss: 4.1267 - perplexity: 75.6702\n",
            "Epoch 149/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4347 - loss: 4.1373 - perplexity: 74.6684\n",
            "Epoch 150/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4338 - loss: 4.1176 - perplexity: 74.9336\n",
            "Epoch 151/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4376 - loss: 4.1606 - perplexity: 76.2818\n",
            "Epoch 152/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4376 - loss: 4.1526 - perplexity: 76.5289\n",
            "Epoch 153/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4422 - loss: 4.1866 - perplexity: 78.3214\n",
            "Epoch 154/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4504 - loss: 4.1495 - perplexity: 75.1528\n",
            "Epoch 155/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4466 - loss: 4.1778 - perplexity: 78.5987\n",
            "Epoch 156/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4527 - loss: 4.2047 - perplexity: 81.1004\n",
            "Epoch 157/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4642 - loss: 4.1548 - perplexity: 79.9723\n",
            "Epoch 158/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4572 - loss: 4.2782 - perplexity: 85.2154\n",
            "Epoch 159/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4588 - loss: 4.2325 - perplexity: 86.0491\n",
            "Epoch 160/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4660 - loss: 4.1803 - perplexity: 77.3013\n",
            "Epoch 161/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4638 - loss: 4.1299 - perplexity: 74.6199\n",
            "Epoch 162/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4649 - loss: 4.0856 - perplexity: 74.6601\n",
            "Epoch 163/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4606 - loss: 4.0316 - perplexity: 69.7838\n",
            "Epoch 164/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4631 - loss: 4.0198 - perplexity: 67.1871\n",
            "Epoch 165/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4638 - loss: 3.9418 - perplexity: 63.1929\n",
            "Epoch 166/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4797 - loss: 3.8938 - perplexity: 59.1599\n",
            "Epoch 167/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4845 - loss: 3.8592 - perplexity: 57.4240\n",
            "Epoch 168/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4756 - loss: 3.9811 - perplexity: 64.7595\n",
            "Epoch 169/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4879 - loss: 3.8785 - perplexity: 61.0110\n",
            "Epoch 170/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4786 - loss: 4.0094 - perplexity: 71.2955\n",
            "Epoch 171/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4871 - loss: 3.9172 - perplexity: 62.3703\n",
            "Epoch 172/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4866 - loss: 3.8983 - perplexity: 61.4139\n",
            "Epoch 173/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4936 - loss: 3.8477 - perplexity: 57.5606\n",
            "Epoch 174/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4940 - loss: 3.8963 - perplexity: 61.4311\n",
            "Epoch 175/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4928 - loss: 3.9303 - perplexity: 61.3993\n",
            "Epoch 176/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5076 - loss: 3.8288 - perplexity: 56.2442\n",
            "Epoch 177/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4967 - loss: 3.8293 - perplexity: 56.2010\n",
            "Epoch 178/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4988 - loss: 3.9142 - perplexity: 61.5397\n",
            "Epoch 179/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.5034 - loss: 3.9239 - perplexity: 60.8201\n",
            "Epoch 180/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4886 - loss: 4.0017 - perplexity: 67.6029\n",
            "Epoch 181/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4956 - loss: 3.9632 - perplexity: 64.3007\n",
            "Epoch 182/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.5098 - loss: 3.9246 - perplexity: 67.1432\n",
            "Epoch 183/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.5002 - loss: 4.0060 - perplexity: 68.6693\n",
            "Epoch 184/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4985 - loss: 4.0586 - perplexity: 75.6236\n",
            "Epoch 185/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.5038 - loss: 4.1110 - perplexity: 81.6691\n",
            "Epoch 186/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.5014 - loss: 4.1473 - perplexity: 75.7043\n",
            "Epoch 187/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5052 - loss: 4.0542 - perplexity: 72.5438\n",
            "Epoch 188/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5145 - loss: 4.0496 - perplexity: 72.9746\n",
            "Epoch 189/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.5350 - loss: 4.0860 - perplexity: 71.0199\n",
            "Epoch 190/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.5363 - loss: 3.9827 - perplexity: 65.9829\n",
            "Epoch 191/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5385 - loss: 3.8902 - perplexity: 63.1671\n",
            "Epoch 192/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.5465 - loss: 3.8033 - perplexity: 57.8189\n",
            "Epoch 193/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.5469 - loss: 3.7581 - perplexity: 50.7507\n",
            "Epoch 194/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.5587 - loss: 3.6296 - perplexity: 45.8477\n",
            "Epoch 195/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5373 - loss: 3.5737 - perplexity: 43.0633\n",
            "Epoch 196/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.5410 - loss: 3.4817 - perplexity: 39.5668\n",
            "Epoch 197/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.5429 - loss: 3.4102 - perplexity: 37.2221\n",
            "Epoch 198/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5351 - loss: 3.3874 - perplexity: 33.7126\n",
            "Epoch 199/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.5401 - loss: 3.2903 - perplexity: 32.6515\n",
            "Epoch 200/200\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.5343 - loss: 3.3412 - perplexity: 34.8608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to a h5 file\n",
        "model.save('poet_model_v4.h5')"
      ],
      "metadata": {
        "id": "5Y4eeoJWRdS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8edac397-21d5-4634-c598-f93dba2b8fbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss per epochs graph\n",
        "plt.plot(r.history['loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tV-cPBZ9R3uW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "4f8611c1-04fb-4edb-cb81-da0233c0be33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the summary of the model\n",
        "r.model.summary()"
      ],
      "metadata": {
        "id": "GNRwYkoISMiP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "b03f66c2-f0bb-4e98-e43a-8cce20003d94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │       \u001b[38;5;34m1,444,350\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m1,357,824\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m2,099,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m262,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9629\u001b[0m)                │       \u001b[38;5;34m4,939,677\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,444,350</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,357,824</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9629</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,939,677</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,207,416\u001b[0m (77.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,207,416</span> (77.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,103,707\u001b[0m (38.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,103,707</span> (38.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m10,103,709\u001b[0m (38.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,103,709</span> (38.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to generate poems based on a seed\n",
        "def generate_poem(seed_text, num_of_words):\n",
        "    poem = seed_text\n",
        "\n",
        "    for i in range(num_of_words):\n",
        "        # convert seed_text to sequences\n",
        "        sequences = tokenizer.texts_to_sequences([seed_text])\n",
        "        # pad sequences such that all sequences are of length SEQ_LENGTH\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=SEQ_LENGTH, truncating='pre')\n",
        "\n",
        "        # predict the next word\n",
        "        prediction = model.predict(padded_sequences)\n",
        "        # get the index of the highest probability\n",
        "        predicted_word_index = np.argmax(prediction, axis=-1)[0]\n",
        "        # convert it back to a word\n",
        "        predicted_word = tokenizer.index_word[predicted_word_index]\n",
        "\n",
        "        # append predicted word to the poem\n",
        "        poem += ' ' + predicted_word\n",
        "\n",
        "        # update seed_text for the next prediction\n",
        "        seed_text = ' '.join(seed_text.split()[1:] + [predicted_word])\n",
        "\n",
        "    return poem\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PiezwLPOaDhw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from the file\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('poet_model_v4.h5')"
      ],
      "metadata": {
        "id": "P_YIHOESQhuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08181f61-a6ac-44c5-f6eb-7b0275230d0f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from a random sequence from training\n",
        "import random\n",
        "seed = random.choice(X_seq)\n",
        "seed = [tokenizer.index_word[token] for token in seed]\n",
        "seed_text = ' '.join(seed)\n",
        "\n",
        "print(seed_text)\n",
        "\n",
        "print(generate_poem(seed_text, 30))\n"
      ],
      "metadata": {
        "id": "dOWKqKoVYURw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12275ad6-fe86-4a7b-8b06-6e04d64bc2d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with the splendour of love's praise the pain the calm and the astonishment desire illimitable and still content and all dear names men use to cheat despair for the perplexed and viewless streams that bear our hearts at random down\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "with the splendour of love's praise the pain the calm and the astonishment desire illimitable and still content and all dear names men use to cheat despair for the perplexed and viewless streams that bear our hearts at random down the what is white still temple after temple down prayers her stomach began to spoke i away he would go do i am be get up a week of battle—in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from a string\n",
        "seed = \"Beneath the canopy of stars, a quiet world sleeps, where dreams are woven in the shadows of ancient trees.\"\n",
        "print(generate_poem(seed, 20))"
      ],
      "metadata": {
        "id": "gYsk6ud6lT0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730f9cb6-b299-4772-eac9-6dcba4fb01df"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Beneath the canopy of stars, a quiet world sleeps, where dreams are woven in the shadows of ancient trees. through the stars who gloriously bright through any on roadsmake after him collapses all for its new on the fallen\n"
          ]
        }
      ]
    }
  ]
}